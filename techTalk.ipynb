{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rose22\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\graph\\graph.py:36: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langgraph.pregel import Channel, Pregel\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"amazon.nova-pro-v1:0\", temperature=0, region_name=\"us-east-1\"):\n",
    "    llm = ChatBedrockConverse(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        max_tokens=None,\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        (\"system\", \"You are an AI assistant.\"),\n",
    "        (\"human\", prompt)\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clara Everett, born in 1992 in Willowbrook, Vermont, is a creative director for a digital design firm in Los Angeles, known for her passion for painting, photography, and digital art, and her work has been exhibited in galleries worldwide.\n"
     ]
    }
   ],
   "source": [
    "text1= \"\"\"\n",
    "You should express what you want a model to do by \n",
    "providing instructions that are as clear and \n",
    "specific as you can possibly make them. \n",
    "This will guide the model towards the desired output, \n",
    "and reduce the chances of receiving irrelevant \n",
    "or incorrect responses. Don't confuse writing a \n",
    "clear prompt with writing a short prompt. \n",
    "In many cases, longer prompts provide more clarity \n",
    "and context for the model, which can lead to \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "My name is Clara Everett, and I was born in the small town of Willowbrook, Vermont, in 1992. From a young age, \n",
    "I was drawn to the arts, particularly painting and photography. I spent my childhood exploring the woods behind our house, \n",
    "capturing the beauty of nature through a lens or a canvas. After high school, I moved to New York City to attend the prestigious Art Institute, \n",
    "where I honed my craft. I graduated with honors in 2014, and shortly after, I began exhibiting my work in local galleries. \n",
    "My early career was a mix of freelance photography and graphic design, but it wasn't until I discovered my passion for \n",
    "digital art that things really took off. In 2017, I moved to Los Angeles, where I became involved in the tech world.\n",
    "I now work as a creative director for a digital design firm, blending my artistic background with cutting-edge technology. \n",
    "Outside of work, I love to travel and explore new cultures, always seeking inspiration for my next project. \n",
    "My art has been displayed in galleries worldwide, but I still find peace in the quiet moments, \n",
    "whether itâ€™s sipping coffee in my studio or walking through the city at dawn.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
